import os
import re
import streamlit as st
from dotenv import load_dotenv

# ---- BASÄ°T Ä°MPORTLAR ----
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import LLMChain
from langchain_community.embeddings import HuggingFaceEmbeddings

# --- .env dosyasÄ±ndaki API anahtarÄ±nÄ± yÃ¼kle ---
load_dotenv()

# --- AKILLI HTML TEMÄ°ZLEME ---
def clean_html_tags(text):
    """Sadece gerÃ§ek HTML tag'lerini temizle"""
    # EÄŸer Ã§ok fazla HTML tag'i yoksa, orijinal metni koru
    html_tag_count = len(re.findall(r'<[^>]+>', text))
    if html_tag_count < 3:  # Ã‡ok az HTML tag varsa temizleme
        return text
    
    # Ã‡ok fazla HTML tag varsa temizle
    clean_text = re.sub(r'<[^>]+>', '', text)
    clean_text = re.sub(r'\s+', ' ', clean_text)
    return clean_text.strip()

# --- 1. Veri YÃ¼kleme ve ParÃ§alama ---
def get_text_chunks(text_file):
    try:
        loader = TextLoader(text_file, encoding="utf-8")
        documents = loader.load()
        
        # HTML tag'lerini temizle
        for doc in documents:
            doc.page_content = clean_html_tags(doc.page_content)
            
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = splitter.split_documents(documents)
        return chunks
    except Exception as e:
        st.error(f"Veri yÃ¼kleme hatasÄ±: {str(e)}")
        return None

# --- 2. VektÃ¶r Deposu (FAISS) oluÅŸturma ---
def get_vector_store(text_chunks):
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)
        vector_store.save_local("faiss_index")
        return vector_store
    except Exception as e:
        st.error(f"VektÃ¶r deposu oluÅŸturma hatasÄ±: {str(e)}")
        return None

# --- 3. TEMÄ°Z YANIT SÄ°STEMÄ° ---
def generate_response(context, question):
    """
    LLM olmadan temiz bir yanÄ±t oluÅŸturucu
    """
    # Context'i temizle
    clean_context = clean_html_tags(context)
    
    # BaÅŸlÄ±k ve badge'leri atla, anlamlÄ± iÃ§eriÄŸi bul
    lines = clean_context.split('\n')
    meaningful_lines = []
    
    for line in lines:
        line = line.strip()
        # AnlamsÄ±z satÄ±rlarÄ± atla
        if len(line) < 10 or line.startswith('http') or 'badge' in line.lower():
            continue
        if len(line.split()) > 3:  # En az 3 kelime iÃ§eren satÄ±rlar
            meaningful_lines.append(line)
    
    meaningful_text = ' '.join(meaningful_lines[:5])  # Ä°lk 5 anlamlÄ± satÄ±r
    
    if not meaningful_text:
        meaningful_text = clean_context[:500]  # Fallback
    
    question_lower = question.lower()
    
    if "nedir" in question_lower or "ne demek" in question_lower:
        return f"{meaningful_text[:400]}... [DevamÄ± iÃ§in detaylÄ± sonuÃ§lara bakÄ±n]"
    
    elif "nasÄ±l" in question_lower or "yapÄ±lÄ±r" in question_lower or "kurulur" in question_lower:
        return f"{meaningful_text[:450]}... [AdÄ±mlar iÃ§in detaylÄ± sonuÃ§larÄ± inceleyin]"
    
    elif "ne iÅŸe yarar" in question_lower or "kullanÄ±m" in question_lower:
        return f"{meaningful_text[:400]}... [KullanÄ±m detaylarÄ± iÃ§in yukarÄ±daki sonuÃ§lara bakÄ±n]"
    
    elif "bileÅŸen" in question_lower or "component" in question_lower:
        return f"{meaningful_text[:380]}... [BileÅŸen listesi iÃ§in detaylÄ± sonuÃ§larÄ± gÃ¶rÃ¼n]"
    
    elif "rag" in question_lower:
        return f"{meaningful_text[:350]}... [RAG mimarisi detaylarÄ± iÃ§in sonuÃ§lara bakÄ±n]"
    
    else:
        return f"{meaningful_text[:500]}... [DetaylÄ± bilgi iÃ§in yukarÄ±daki sonuÃ§larÄ± okuyun]"

# --- 4. KullanÄ±cÄ± Sorusunu YanÄ±tlama ---
def user_input(user_question):
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        if not os.path.exists("faiss_index"):
            st.error("FAISS index bulunamadÄ±. LÃ¼tfen Ã¶nce index oluÅŸturun.")
            return
            
        new_db = FAISS.load_local("faiss_index", embeddings)
        docs = new_db.similarity_search(user_question, k=3)
        
        st.success(f"âœ… '{user_question}' sorusu iÃ§in {len(docs)} sonuÃ§ bulundu:")
        
        # TÃ¼m dokÃ¼manlarÄ± birleÅŸtir ve temizle
        all_context = "\n".join([doc.page_content for doc in docs])
        
        # Temiz yanÄ±t oluÅŸtur
        with st.spinner("YanÄ±t oluÅŸturuluyor..."):
            response = generate_response(all_context, user_question)
            
            st.info("ğŸ’¡ **YanÄ±t:**")
            st.write(response)
        
        # DetaylÄ± ve TEMÄ°Z sonuÃ§lar
        st.divider()
        st.subheader("ğŸ“„ DetaylÄ± SonuÃ§lar")
        
        for i, doc in enumerate(docs):
            clean_content = clean_html_tags(doc.page_content)
            # Ã‡ok kÄ±sa iÃ§erikleri filtrele
            if len(clean_content) > 50:
                with st.expander(f"ğŸ“– SonuÃ§ {i+1}"):
                    st.write(clean_content)
        
    except Exception as e:
        st.error(f"Hata: {str(e)}")

# --- STREAMLIT ARAYÃœZÃœ ---
st.set_page_config(
    page_title="Akbank GenAI Chatbot",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.header("ğŸ¤– Akbank GenAI Bootcamp Projesi: RAG Chatbot")

# Session state
if 'current_question' not in st.session_state:
    st.session_state.current_question = ""

# Sidebar
with st.sidebar:
    st.subheader("ğŸ“‹ Proje Bilgisi")
    st.write("RAG (Retrieval Augmented Generation) tabanlÄ± chatbot")
    st.write("**Veri:** LangChain dokÃ¼mantasyonu")
    
    st.divider()
    
    st.subheader("âš™ï¸ Sistem")
    
    if st.button("ğŸ”„ Index'i Temizle ve Yeniden OluÅŸtur", use_container_width=True):
        if os.path.exists("faiss_index"):
            import shutil
            try:
                shutil.rmtree("faiss_index")
                st.success("âœ… Eski index temizlendi!")
            except Exception as e:
                st.error(f"Silme hatasÄ±: {str(e)}")
        
        with st.spinner("Temiz index oluÅŸturuluyor..."):
            try:
                text_chunks = get_text_chunks("data.txt")
                if text_chunks:
                    vector_store = get_vector_store(text_chunks)
                    if vector_store:
                        st.success("âœ… Temiz index oluÅŸturuldu!")
                    else:
                        st.error("âŒ Index oluÅŸturulamadÄ±!")
                else:
                    st.error("âŒ Veri yÃ¼klenemedi!")
            except Exception as e:
                st.error(f"Hata: {str(e)}")

# Ana iÃ§erik
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ’¬ Sohbet")
    
    if os.path.exists("faiss_index"):
        st.success("âœ… Sistem hazÄ±r! SorularÄ±nÄ±zÄ± sorabilirsiniz.")
    else:
        st.warning("âš ï¸ LÃ¼tfen Ã¶nce sidebar'dan index oluÅŸturun!")
    
    st.divider()
    
    user_question = st.text_input(
        "LangChain hakkÄ±nda sorunuzu girin:",
        placeholder="Ã–rnek: LangChain nedir? NasÄ±l kullanÄ±lÄ±r?",
        key="question_input"
    )
    
    if st.session_state.current_question:
        user_question = st.session_state.current_question
        st.session_state.current_question = ""
    
    if user_question:
        user_input(user_question)

with col2:
    st.subheader("ğŸš€ Ã–rnek Sorular")
    
    examples = [
        "LangChain nedir?",
        "LangChain nasÄ±l kurulur?",
        "LangChain ne iÅŸe yarar?",
        "LangChain'in temel bileÅŸenleri nelerdir?",
        "RAG (Retrieval Augmented Generation) nedir?",
        "LangChain ile neler yapÄ±labilir?"
    ]
    
    for example in examples:
        if st.button(example, key=example, use_container_width=True):
            st.session_state.current_question = example
            st.rerun()

# Footer
st.divider()
st.caption("Akbank GenAI Bootcamp - RAG Chatbot | TemizlenmiÅŸ Ä°Ã§erik")

# Debug
with st.expander("ğŸ”§ Sistem Durumu"):
    st.write(f"FAISS Index: {'âœ… Var' if os.path.exists('faiss_index') else 'âŒ Yok'}")
    st.write(f"Data.txt: {'âœ… Var' if os.path.exists('data.txt') else 'âŒ Yok'}")